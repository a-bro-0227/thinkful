---
title: Architecture of artificial neural networks
author: Thinkful
team: grading
time: 120 minutes
uuid: 80c311bc-05e5-46d3-b1e6-492c7d368a99
timeHours: 2
---

In this checkpoint, you'll be introduced to the fundamental architecture of artificial neural networks (ANNs). The architecture that you'll learn about in this checkpoint is also known as a *multilayer perceptron* or *feedforward network*, and the ideas presented here constitute the backbone of most deep-learning models.

This type of neural network is relatively easy to understand conceptually. In many real-world tasks, however, other architecture types of neural networks are preferred over this one. Yet, it's crucial to understand this architecture before mastering the other deep-learning models. In this module, your focus will be on the ANNs.

For a refresher on what neural networks look like, look at this image from the previous checkpoint:

![multiple layers](multiple_layers.png)

The circles in the figure above are called *neurons*, and the neurons grouped together are called the *layers*. You'll start exploring ANNs with the neurons.

<jupyter notebook-name="2.architecture_of_ann" course-code="DSBC"></jupyter>

For a visual overview of how ANNs work, check out the below video.


<iframe id="kaltura_player_1604701778" src="https://cdnapisec.kaltura.com/p/2315191/sp/231519100/embedIframeJs/uiconf_id/45331192/partner_id/2315191?iframeembed=true&playerId=kaltura_player_1604701778&entry_id=1_bgx5yefy" width="100%" height="500" allowfullscreen webkitallowfullscreen mozAllowFullScreen allow="autoplay *; fullscreen *; encrypted-media *" frameborder="0"></iframe>